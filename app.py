import streamlit as st
import asyncio
import os
import csv
import time
import zipfile
import io
from date_utils import parse_date
from download_api import download_vessel_track_data
from path_utils import get_output_dir_path

# --- ç¶²é è¨­å®š ---
st.set_page_config(page_title="èˆ¹èˆ¶è»Œè·¡ä¸‹è¼‰ç¥å™¨", page_icon="ğŸš¢")

st.title("ğŸš¢ èˆ¹èˆ¶è»Œè·¡è³‡æ–™æ‰¹æ¬¡ä¸‹è¼‰")
st.markdown("è¼¸å…¥ MMSI èˆ‡æ—¥æœŸï¼Œç³»çµ±å°‡è‡ªå‹•æŠ“å– MarineTraffic è³‡æ–™ä¸¦æ‰“åŒ…ä¸‹è¼‰ã€‚")

# --- å´é‚Šæ¬„è¨­å®š (è¼¸å…¥å€) ---
with st.sidebar:
    st.header("âš™ï¸ åƒæ•¸è¨­å®š")
    
    # API Key è¼¸å…¥ (è¨­ç‚ºå¯†ç¢¼æ ¼å¼ï¼Œéš±è—èµ·ä¾†)
    api_key = st.text_input("MarineTraffic API Key", type="password", help="è«‹è¼¸å…¥æ‚¨çš„ API é‡‘é‘°")
    
    # æ—¥æœŸé¸æ“‡
    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input("é–‹å§‹æ—¥æœŸ", value=parse_date("2023-01-01"))
    with col2:
        end_date = st.date_input("çµæŸæ—¥æœŸ", value=parse_date("2023-01-05"))
        
    # é–“éš”è¨­å®š
    sleep_sec = st.number_input("æ¯è‰˜èˆ¹é–“éš” (ç§’)", min_value=1, value=30, help="é¿å…è«‹æ±‚å¤ªå¿«è¢«å°é–ï¼Œå»ºè­° 30 ç§’ä»¥ä¸Š")
    
    st.info("ğŸ’¡ å»ºè­°ï¼šå¤§é‡ä¸‹è¼‰æ™‚è«‹è€å¿ƒç­‰å€™ï¼Œåˆ‡å‹¿é—œé–‰è¦–çª—ã€‚")

# --- ä¸»è¦å…§å®¹å€ ---
st.subheader("ğŸ“‹ MMSI æ¸…å–®")
mmsi_input = st.text_area("è«‹è¼¸å…¥ MMSI (ä¸€è¡Œä¸€è‰˜)", height=150, placeholder="416123456\n416987654")

# --- ä¸‹è¼‰é‚è¼¯ ---
async def process_download(api_key, mmsi_list, start_dt, end_dt, sleep_sec, log_container):
    temp_dir = "./temp_web"
    results = [] # å­˜æ”¾ç”Ÿæˆçš„ CSV å…§å®¹
    
    # é€²åº¦æ¢
    progress_bar = st.progress(0)
    
    for index, mmsi in enumerate(mmsi_list):
        current_num = index + 1
        total = len(mmsi_list)
        
        log_container.write(f"â³ [{current_num}/{total}] æ­£åœ¨è™•ç† MMSI: {mmsi} ...")
        
        # é‡è©¦æ©Ÿåˆ¶
        max_retries = 2
        success = False
        
        for attempt in range(1, max_retries + 1):
            try:
                # é€™è£¡è¦ç¨å¾®æ”¹å¯« download_api ä»¥é©æ‡‰ stream (æˆ–ç›´æ¥å­˜æš«å­˜æª”)
                # ç‚ºäº†ç°¡å–®ï¼Œæˆ‘å€‘å…ˆå­˜æœ¬æ©Ÿæš«å­˜ï¼Œå†è®€å–
                res = await download_vessel_track_data(api_key, mmsi, start_dt, end_dt, temp_dir)
                
                if res:
                    # è®€å–å‰›å‰›ä¸‹è¼‰ä¸¦åˆä½µå¥½çš„æª”æ¡ˆ (éœ€è‡ªè¡Œå¯¦ä½œåˆä½µé‚è¼¯æˆ–æ˜¯ç°¡åŒ–)
                    # é€™è£¡ç°¡åŒ–é‚è¼¯ï¼šå‡è¨­ download_api æœƒç”¢å‡ºç‰‡æ®µï¼Œæˆ‘å€‘éœ€è¦åˆä½µ
                    # ç‚ºäº†ç¶²é ç‰ˆæ•ˆç‡ï¼Œå»ºè­°ç›´æ¥å›å‚³æ•¸æ“šï¼Œä½†è‹¥æ²¿ç”¨èˆŠæ¶æ§‹ï¼š
                    output_dir = get_output_dir_path(mmsi, temp_dir)
                    if os.path.exists(output_dir):
                        # åˆä½µè¨˜æ†¶é«”ä¸­çš„ CSV
                        csv_buffer = io.StringIO()
                        writer = None
                        all_files = sorted([f for f in os.listdir(output_dir) if f.endswith(".csv")])
                        
                        header_saved = False
                        for f in all_files:
                            with open(os.path.join(output_dir, f), "r", encoding="utf-8") as infile:
                                reader = csv.reader(infile)
                                try:
                                    header = next(reader)
                                    if not header_saved:
                                        writer = csv.writer(csv_buffer)
                                        writer.writerow(header)
                                        header_saved = True
                                    for row in reader:
                                        writer.writerow(row)
                                except StopIteration:
                                    pass
                        
                        results.append({"filename": f"vessel_{mmsi}.csv", "data": csv_buffer.getvalue()})
                        log_container.write(f"âœ… {mmsi} ä¸‹è¼‰æˆåŠŸï¼")
                        success = True
                        break
            except Exception as e:
                 log_container.error(f"âŒ {mmsi} éŒ¯èª¤: {e}")
            
            if not success and attempt < max_retries:
                log_container.warning(f"â„ï¸ å†·å»ä¸­ (120s)...")
                time.sleep(120)

        # æ›´æ–°é€²åº¦æ¢
        progress_bar.progress(current_num / total)

        # é–“éš”ä¼‘æ¯
        if current_num < total and success:
             time.sleep(sleep_sec)
    
    return results

# --- æŒ‰éˆ•è§¸ç™¼ ---
if st.button("ğŸš€ é–‹å§‹ä¸‹è¼‰"):
    if not api_key:
        st.error("è«‹è¼¸å…¥ API Key")
    elif not mmsi_input.strip():
        st.error("è«‹è¼¸å…¥ MMSI")
    else:
        mmsi_list = [x.strip() for x in mmsi_input.split('\n') if x.strip()]
        
        log_box = st.empty() # å»ºç«‹ä¸€å€‹ç©ºå®¹å™¨æ”¾ Log
        
        # åŸ·è¡Œç•°æ­¥ä»»å‹™
        results = asyncio.run(process_download(api_key, mmsi_list, start_date, end_date, sleep_sec, log_box))
        
        if results:
            st.success(f"ğŸ‰ è™•ç†å®Œæˆï¼å…±æˆåŠŸ {len(results)} è‰˜ã€‚")
            
            # æ‰“åŒ…æˆ ZIP
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, "w") as zf:
                for item in results:
                    zf.writestr(item["filename"], item["data"])
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ ZIP å£“ç¸®æª”",
                data=zip_buffer.getvalue(),
                file_name="vessel_tracks.zip",
                mime="application/zip"
            )
        else:
            st.warning("æ²’æœ‰æˆåŠŸä¸‹è¼‰ä»»ä½•è³‡æ–™ã€‚")